{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQfNcgJ0q/DRBrb6UctE44",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhrazKhan31/Deep-Learning-Lab/blob/main/Experiment4_Text_Generation_using_RNN_and_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YPzvSjcUyUZ7"
      },
      "outputs": [],
      "source": [
        "# Basic imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb2FUqzbypkc",
        "outputId": "3120e156-c5e4-49f6-f82f-4c4fd996fe8e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.1.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/imbikramsaha/poems/data?select=poems-100.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqt_22Ypy62V",
        "outputId": "dd1d9a9a-a4a8-48ae-b8c7-e080bab36b8a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: ahrazkh31\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/imbikramsaha/poems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"/content/poems/poems-100.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qwUX0LdDy-AO",
        "outputId": "b0364355-057f-4756-9539-4dd6ec45e32b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  O my Luve's like a red, red rose\\nThat’s newly...\n",
              "1  The rose is red,\\nThe violet's blue,\\nSugar is...\n",
              "2  How do I love thee? Let me count the ways.\\nI ...\n",
              "3  Had I the heavens' embroidered cloths,\\nEnwrou...\n",
              "4  I.\\n    Enough! we're tired, my heart and I.\\n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77646ef3-085c-4985-9ba2-1c80439607ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O my Luve's like a red, red rose\\nThat’s newly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The rose is red,\\nThe violet's blue,\\nSugar is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do I love thee? Let me count the ways.\\nI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Had I the heavens' embroidered cloths,\\nEnwrou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I.\\n    Enough! we're tired, my heart and I.\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77646ef3-085c-4985-9ba2-1c80439607ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77646ef3-085c-4985-9ba2-1c80439607ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77646ef3-085c-4985-9ba2-1c80439607ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b182fa93-994c-4711-9fdf-0f71101df3f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b182fa93-994c-4711-9fdf-0f71101df3f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b182fa93-994c-4711-9fdf-0f71101df3f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Three little birds in a row\\nSat musing.\\nA man passed near that place.\\nThen did the little birds nudge each other.\\n\\nThey said, \\\"He thinks he can sing.\\\"\\nThey threw back their heads to laugh.\\nWith quaint countenances\\nThey regarded him.\\nThey were very curious,\\nThose three little birds in a row.\",\n          \"  I think I could turn and live with animals, they are so placid and\\n      self-contain'd,\\n  I stand and look at them long and long.\\n\\n  They do not sweat and whine about their condition,\\n  They do not lie awake in the dark and weep for their sins,\\n  They do not make me sick discussing their duty to God,\\n  Not one is dissatisfied, not one is demented with the mania of\\n      owning things,\\n  Not one kneels to another, nor to his kind that lived thousands of\\n      years ago,\\n  Not one is respectable or unhappy over the whole earth.\\n\\n  So they show their relations to me and I accept them,\\n  They bring me tokens of myself, they evince them plainly in their\\n      possession.\\n\\n  I wonder where they get those tokens,\\n  Did I pass that way huge times ago and negligently drop them?\\n\\n  Myself moving forward then and now and forever,\\n  Gathering and showing more always and with velocity,\\n  Infinite and omnigenous, and the like of these among them,\\n  Not too exclusive toward the reachers of my remembrancers,\\n  Picking out here one that I love, and now go with him on brotherly terms.\\n\\n  A gigantic beauty of a stallion, fresh and responsive to my caresses,\\n  Head high in the forehead, wide between the ears,\\n  Limbs glossy and supple, tail dusting the ground,\\n  Eyes full of sparkling wickedness, ears finely cut, flexibly moving.\\n\\n  His nostrils dilate as my heels embrace him,\\n  His well-built limbs tremble with pleasure as we race around and return.\\n\\n  I but use you a minute, then I resign you, stallion,\\n  Why do I need your paces when I myself out-gallop them?\\n  Even as I stand or sit passing faster than you.\",\n          \"  And as to you Death, and you bitter hug of mortality, it is idle to\\n      try to alarm me.\\n\\n  To his work without flinching the accoucheur comes,\\n  I see the elder-hand pressing receiving supporting,\\n  I recline by the sills of the exquisite flexible doors,\\n  And mark the outlet, and mark the relief and escape.\\n\\n  And as to you Corpse I think you are good manure, but that does not\\n      offend me,\\n  I smell the white roses sweet-scented and growing,\\n  I reach to the leafy lips, I reach to the polish'd breasts of melons.\\n\\n  And as to you Life I reckon you are the leavings of many deaths,\\n  (No doubt I have died myself ten thousand times before.)\\n\\n  I hear you whispering there O stars of heaven,\\n  O suns\\u2014O grass of graves\\u2014O perpetual transfers and promotions,\\n  If you do not say any thing how can I say any thing?\\n\\n  Of the turbid pool that lies in the autumn forest,\\n  Of the moon that descends the steeps of the soughing twilight,\\n  Toss, sparkles of day and dusk\\u2014toss on the black stems that decay\\n      in the muck,\\n  Toss to the moaning gibberish of the dry limbs.\\n\\n  I ascend from the moon, I ascend from the night,\\n  I perceive that the ghastly glimmer is noonday sunbeams reflected,\\n  And debouch to the steady and central from the offspring great or small.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding Approach\n",
        "# Load your dataset (assuming it’s a CSV or TXT file with poems in a 'text' column)\n",
        "data_path = '/content/poems/poems-100.csv'  # Update the path\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    text_data = f.read().lower()\n",
        "\n",
        "# Split the text into lines\n",
        "lines = text_data.split('\\n')\n",
        "print(f'Total lines of poetry: {len(lines)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alSJZsIQzQdP",
        "outputId": "e6fe193c-7cd8-4cdd-9809-9bb2b3928ce1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total lines of poetry: 3426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess text: Remove punctuation and tokenize\n",
        "def clean_and_tokenize(line):\n",
        "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "    return line.split()\n",
        "\n",
        "# Tokenize each line\n",
        "tokenized_lines = [clean_and_tokenize(line) for line in lines if line.strip() != '']\n",
        "print(f'First tokenized line: {tokenized_lines[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wsFUbLyzpbE",
        "outputId": "ab0bfe83-a940-4e1e-f15a-a92b7b660cd3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First tokenized line: ['text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten tokenized list and create vocabulary\n",
        "all_tokens = [token for line in tokenized_lines for token in line]\n",
        "vocabulary = sorted(set(all_tokens))  # Unique words\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "# Create word-to-index and index-to-word dictionaries\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
        "\n",
        "print(f'Size of vocabulary: {vocab_size}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjX9ZRkizvE1",
        "outputId": "e89a9992-b02e-4a25-88e7-38cf4d970f35"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 5503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode_sequence(sequence, vocab_size, word_to_index):\n",
        "    encoded_sequence = []\n",
        "    for token in sequence:\n",
        "        one_hot_vector = np.zeros(vocab_size, dtype=int)\n",
        "        if token in word_to_index:\n",
        "            one_hot_vector[word_to_index[token]] = 1\n",
        "        encoded_sequence.append(one_hot_vector)\n",
        "    return np.array(encoded_sequence)\n",
        "\n",
        "# Example usage for one line\n",
        "example_seq = tokenized_lines[0]\n",
        "encoded_seq = one_hot_encode_sequence(example_seq, vocab_size, word_to_index)\n",
        "print(f'One-hot encoded example sequence shape: {encoded_seq.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Rfj0kjz3Rk",
        "outputId": "b1a28955-403a-4582-a0d5-ea48d08cbc40"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-hot encoded example sequence shape: (1, 5503)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare input-output pairs\n",
        "def create_sequences(tokenized_lines, sequence_length):\n",
        "    X, y = [], []\n",
        "    for line in tokenized_lines:\n",
        "        if len(line) <= sequence_length:\n",
        "            continue\n",
        "        for i in range(len(line) - sequence_length):\n",
        "            sequence = line[i:i+sequence_length]\n",
        "            target = line[i+sequence_length]\n",
        "            X.append(one_hot_encode_sequence(sequence, vocab_size, word_to_index))\n",
        "            y.append(word_to_index[target])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Define sequence length\n",
        "sequence_length = 5  # Use 5 words as input\n",
        "X, y = create_sequences(tokenized_lines, sequence_length)\n",
        "\n",
        "# Convert to tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)  # Shape: [num_samples, seq_len, vocab_size]\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)     # Shape: [num_samples]\n",
        "\n",
        "print(f'Training data shape: {X_tensor.shape}, Target shape: {y_tensor.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR5zy_tqz7mA",
        "outputId": "1b0b89c9-fd3d-42a6-ffdf-a29fe8ae259d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: torch.Size([10588, 5, 5503]), Target shape: torch.Size([10588])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerationModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, model_type='RNN'):\n",
        "        super(TextGenerationModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.model_type = model_type\n",
        "\n",
        "        if model_type == 'RNN':\n",
        "            self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        elif model_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initial hidden state\n",
        "        # The following lines were modified to create a 3D hidden state for LSTM\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device) # Added for LSTM\n",
        "\n",
        "        if self.model_type == 'RNN':\n",
        "            # Pass h0 directly for RNN, not as a tuple\n",
        "            out, _ = self.rnn(x, h0)\n",
        "        else:\n",
        "            # Pass h0 and c0 as a tuple for LSTM\n",
        "            out, _ = self.rnn(x, (h0, c0)) # Modified for LSTM\n",
        "\n",
        "        # Get the output of the last time step\n",
        "        out = self.fc(out[:, -1, :])  # Shape: [batch_size, output_size]\n",
        "        return out"
      ],
      "metadata": {
        "id": "Rwo-7aF2z-nw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Model Implementation\n",
        "# Model parameters\n",
        "input_size = vocab_size\n",
        "hidden_size = 128\n",
        "output_size = vocab_size\n",
        "num_layers = 2\n",
        "model_type = 'RNN'  # Choose between 'RNN' and 'LSTM'\n",
        "\n",
        "# Initialize model\n",
        "model = TextGenerationModel(input_size, hidden_size, output_size, num_layers, model_type)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "z4YR1l-c0OKS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "\n",
        "# Create DataLoader for batches\n",
        "class PoetryDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Load dataset\n",
        "dataset = PoetryDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OobbhCod0m_m",
        "outputId": "dad70439-d779-4adc-dd12-c8d0c5648e5e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/20], Loss: 5.2130\n",
            "Epoch [10/20], Loss: 3.7123\n",
            "Epoch [15/20], Loss: 1.4804\n",
            "Epoch [20/20], Loss: 0.6107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_sequence, vocab_dict, index_to_word, vocab_size, max_len=20):\n",
        "    model.eval()\n",
        "    sequence = start_sequence\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        # Encode the sequence\n",
        "        encoded_seq = one_hot_encode_sequence(sequence, vocab_size, vocab_dict)\n",
        "        encoded_seq = torch.tensor(encoded_seq, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "        # Predict the next word\n",
        "        with torch.no_grad():\n",
        "            output = model(encoded_seq)\n",
        "            predicted_idx = torch.argmax(output, dim=1).item()\n",
        "            predicted_word = index_to_word[predicted_idx]\n",
        "\n",
        "        # Add predicted word to sequence\n",
        "        sequence.append(predicted_word)\n",
        "\n",
        "        # Limit sequence length to sliding window\n",
        "        sequence = sequence[1:]\n",
        "\n",
        "    return ' '.join(sequence)\n"
      ],
      "metadata": {
        "id": "_k2t9hqN1d_-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting sequence for prediction\n",
        "start_sequence = ['hello', 'my', 'name', 'is', 'pytorch']\n",
        "generated_text = generate_text(model, start_sequence, word_to_index, index_to_word, vocab_size, max_len=10)\n",
        "print(f'Generated text: {generated_text}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmYcRFpS1tb3",
        "outputId": "18eaf5bd-9e0f-42cb-f099-bbe8b44a95da"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: wag with them—i the are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model Implementation\n",
        "# Model parameters\n",
        "input_size = vocab_size\n",
        "hidden_size = 128\n",
        "output_size = vocab_size\n",
        "num_layers = 2\n",
        "model_type = 'LSTM'  # Choose between 'RNN' and 'LSTM'\n",
        "\n",
        "# Initialize model\n",
        "model = TextGenerationModel(input_size, hidden_size, output_size, num_layers, model_type)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "9kYf96JlMMT9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "\n",
        "# Create DataLoader for batches\n",
        "class PoetryDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Load dataset\n",
        "dataset = PoetryDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUgSeuOkMQ_B",
        "outputId": "bf2c5a58-b287-49f0-ab2a-a0bd9d4bb7d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/20], Loss: 6.8280\n",
            "Epoch [10/20], Loss: 5.3971\n",
            "Epoch [15/20], Loss: 3.9619\n",
            "Epoch [20/20], Loss: 3.4259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_sequence, vocab_dict, index_to_word, vocab_size, max_len=20):\n",
        "    model.eval()\n",
        "    sequence = start_sequence\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        # Encode the sequence\n",
        "        encoded_seq = one_hot_encode_sequence(sequence, vocab_size, vocab_dict)\n",
        "        encoded_seq = torch.tensor(encoded_seq, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "        # Predict the next word\n",
        "        with torch.no_grad():\n",
        "            output = model(encoded_seq)\n",
        "            predicted_idx = torch.argmax(output, dim=1).item()\n",
        "            predicted_word = index_to_word[predicted_idx]\n",
        "\n",
        "        # Add predicted word to sequence\n",
        "        sequence.append(predicted_word)\n",
        "\n",
        "        # Limit sequence length to sliding window\n",
        "        sequence = sequence[1:]\n",
        "\n",
        "    return ' '.join(sequence)"
      ],
      "metadata": {
        "id": "n6RtDAJaMj64"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting sequence for prediction\n",
        "start_sequence = ['hello', 'my', 'name', 'is', 'pytorch']\n",
        "generated_text = generate_text(model, start_sequence, word_to_index, index_to_word, vocab_size, max_len=10)\n",
        "print(f'Generated text: {generated_text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6axS1p0FMrIG",
        "outputId": "771b1957-d3dc-41de-d033-b0f8de9efda9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: be i less in me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainable Word Embeddings Approach\n",
        "# Basic imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import string"
      ],
      "metadata": {
        "id": "3zRlV9u_1xgG"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc6FlxKrIHRz",
        "outputId": "b44ca70c-73ce-4ea0-a7f3-98f266a4797d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.11/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.1.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/imbikramsaha/poems/data?select=poems-100.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THkUd0QkIL97",
        "outputId": "755beac7-e13b-4093-bab9-26618a676e32"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./poems\" (use force=True to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"/content/poems/poems-100.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ztai4LvvIQRj",
        "outputId": "c510259f-dab0-419b-861e-91d0ce7f37cf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  O my Luve's like a red, red rose\\nThat’s newly...\n",
              "1  The rose is red,\\nThe violet's blue,\\nSugar is...\n",
              "2  How do I love thee? Let me count the ways.\\nI ...\n",
              "3  Had I the heavens' embroidered cloths,\\nEnwrou...\n",
              "4  I.\\n    Enough! we're tired, my heart and I.\\n..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61eb1b94-14de-4559-ba38-9a94377cae69\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>O my Luve's like a red, red rose\\nThat’s newly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The rose is red,\\nThe violet's blue,\\nSugar is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How do I love thee? Let me count the ways.\\nI ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Had I the heavens' embroidered cloths,\\nEnwrou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I.\\n    Enough! we're tired, my heart and I.\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61eb1b94-14de-4559-ba38-9a94377cae69')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61eb1b94-14de-4559-ba38-9a94377cae69 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61eb1b94-14de-4559-ba38-9a94377cae69');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-deb09ce1-8706-4979-b712-490a408eb2b2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-deb09ce1-8706-4979-b712-490a408eb2b2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-deb09ce1-8706-4979-b712-490a408eb2b2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Three little birds in a row\\nSat musing.\\nA man passed near that place.\\nThen did the little birds nudge each other.\\n\\nThey said, \\\"He thinks he can sing.\\\"\\nThey threw back their heads to laugh.\\nWith quaint countenances\\nThey regarded him.\\nThey were very curious,\\nThose three little birds in a row.\",\n          \"  I think I could turn and live with animals, they are so placid and\\n      self-contain'd,\\n  I stand and look at them long and long.\\n\\n  They do not sweat and whine about their condition,\\n  They do not lie awake in the dark and weep for their sins,\\n  They do not make me sick discussing their duty to God,\\n  Not one is dissatisfied, not one is demented with the mania of\\n      owning things,\\n  Not one kneels to another, nor to his kind that lived thousands of\\n      years ago,\\n  Not one is respectable or unhappy over the whole earth.\\n\\n  So they show their relations to me and I accept them,\\n  They bring me tokens of myself, they evince them plainly in their\\n      possession.\\n\\n  I wonder where they get those tokens,\\n  Did I pass that way huge times ago and negligently drop them?\\n\\n  Myself moving forward then and now and forever,\\n  Gathering and showing more always and with velocity,\\n  Infinite and omnigenous, and the like of these among them,\\n  Not too exclusive toward the reachers of my remembrancers,\\n  Picking out here one that I love, and now go with him on brotherly terms.\\n\\n  A gigantic beauty of a stallion, fresh and responsive to my caresses,\\n  Head high in the forehead, wide between the ears,\\n  Limbs glossy and supple, tail dusting the ground,\\n  Eyes full of sparkling wickedness, ears finely cut, flexibly moving.\\n\\n  His nostrils dilate as my heels embrace him,\\n  His well-built limbs tremble with pleasure as we race around and return.\\n\\n  I but use you a minute, then I resign you, stallion,\\n  Why do I need your paces when I myself out-gallop them?\\n  Even as I stand or sit passing faster than you.\",\n          \"  And as to you Death, and you bitter hug of mortality, it is idle to\\n      try to alarm me.\\n\\n  To his work without flinching the accoucheur comes,\\n  I see the elder-hand pressing receiving supporting,\\n  I recline by the sills of the exquisite flexible doors,\\n  And mark the outlet, and mark the relief and escape.\\n\\n  And as to you Corpse I think you are good manure, but that does not\\n      offend me,\\n  I smell the white roses sweet-scented and growing,\\n  I reach to the leafy lips, I reach to the polish'd breasts of melons.\\n\\n  And as to you Life I reckon you are the leavings of many deaths,\\n  (No doubt I have died myself ten thousand times before.)\\n\\n  I hear you whispering there O stars of heaven,\\n  O suns\\u2014O grass of graves\\u2014O perpetual transfers and promotions,\\n  If you do not say any thing how can I say any thing?\\n\\n  Of the turbid pool that lies in the autumn forest,\\n  Of the moon that descends the steeps of the soughing twilight,\\n  Toss, sparkles of day and dusk\\u2014toss on the black stems that decay\\n      in the muck,\\n  Toss to the moaning gibberish of the dry limbs.\\n\\n  I ascend from the moon, I ascend from the night,\\n  I perceive that the ghastly glimmer is noonday sunbeams reflected,\\n  And debouch to the steady and central from the offspring great or small.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset (assuming it’s a CSV or TXT file with poems in a 'text' column)\n",
        "data_path = '/content/poems/poems-100.csv'  # Update the path\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    text_data = f.read().lower()\n",
        "\n",
        "# Split the text into lines\n",
        "lines = text_data.split('\\n')\n",
        "print(f'Total lines of poetry: {len(lines)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HenJcAf5IU8y",
        "outputId": "55bf2c39-b382-4848-c5bc-43d857835944"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total lines of poetry: 3426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess text: Remove punctuation and tokenize\n",
        "def clean_and_tokenize(line):\n",
        "    line = line.translate(str.maketrans('', '', string.punctuation))\n",
        "    return line.split()\n",
        "\n",
        "# Tokenize each line\n",
        "tokenized_lines = [clean_and_tokenize(line) for line in lines if line.strip() != '']\n",
        "print(f'First tokenized line: {tokenized_lines[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1bGk-vtImlJ",
        "outputId": "8a5aad2c-1318-4dbe-8a02-020cd0a818ef"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First tokenized line: ['text']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten tokenized list and create vocabulary\n",
        "all_tokens = [token for line in tokenized_lines for token in line]\n",
        "vocabulary = sorted(set(all_tokens))  # Unique words\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "# Create word-to-index and index-to-word dictionaries\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocabulary)}\n",
        "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
        "\n",
        "print(f'Size of vocabulary: {vocab_size}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JAxISaWIpxS",
        "outputId": "1bf7bf46-6e10-49c0-8e33-f350681739be"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of vocabulary: 5503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokenized lines to indexed sequences\n",
        "def convert_to_index_sequence(line, word_to_index):\n",
        "    return [word_to_index[token] for token in line if token in word_to_index]\n",
        "\n",
        "# Create indexed sequences and targets\n",
        "def create_sequences(tokenized_lines, sequence_length):\n",
        "    X, y = [], []\n",
        "    for line in tokenized_lines:\n",
        "        indexed_sequence = convert_to_index_sequence(line, word_to_index)\n",
        "        if len(indexed_sequence) <= sequence_length:\n",
        "            continue\n",
        "        for i in range(len(indexed_sequence) - sequence_length):\n",
        "            sequence = indexed_sequence[i:i+sequence_length]\n",
        "            target = indexed_sequence[i+sequence_length]\n",
        "            X.append(sequence)\n",
        "            y.append(target)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Define sequence length\n",
        "sequence_length = 5  # Use 5 words as input\n",
        "X, y = create_sequences(tokenized_lines, sequence_length)\n",
        "\n",
        "# Convert to tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.long)   # Shape: [num_samples, seq_len]\n",
        "y_tensor = torch.tensor(y, dtype=torch.long)   # Shape: [num_samples]\n",
        "\n",
        "print(f'Training data shape: {X_tensor.shape}, Target shape: {y_tensor.shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XhNkFQZItLw",
        "outputId": "f42efd42-e925-484e-f252-a2bf6040faed"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: torch.Size([10588, 5]), Target shape: torch.Size([10588])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingRNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, num_layers=1, model_type='RNN'):\n",
        "        super(EmbeddingRNNModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.model_type = model_type\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # RNN or LSTM layer\n",
        "        if model_type == 'RNN':\n",
        "            self.rnn = nn.RNN(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
        "        elif model_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "        # Fully connected layer to predict next word\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding lookup\n",
        "        embedded = self.embedding(x)  # Shape: [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # Initial hidden state\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        if self.model_type == 'LSTM':\n",
        "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "            out, _ = self.rnn(embedded, (h0, c0))\n",
        "        else:\n",
        "            out, _ = self.rnn(embedded, h0)\n",
        "\n",
        "        # Get the output of the last time step\n",
        "        out = self.fc(out[:, -1, :])  # Shape: [batch_size, output_size]\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "yCMTFV2bIwCf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model Implementation\n",
        "# Model parameters\n",
        "embedding_dim = 64    # Embedding dimension\n",
        "hidden_size = 128     # Hidden size of RNN/LSTM\n",
        "output_size = vocab_size\n",
        "num_layers = 2\n",
        "model_type = 'LSTM'  # Choose between 'RNN' and 'LSTM'\n",
        "\n",
        "# Instantiate model\n",
        "model = EmbeddingRNNModel(vocab_size, embedding_dim, hidden_size, output_size, num_layers, model_type)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "c4jDnrXZI2dI"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset\n",
        "class PoetryDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = PoetryDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "id": "zjHZ6EhTI6wX"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_epochs = 20\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKqdhO1gI_8m",
        "outputId": "fb29d38a-0c23-4a81-f27c-5d9f8ad20d71"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/20], Loss: 5.4182\n",
            "Epoch [10/20], Loss: 4.7538\n",
            "Epoch [15/20], Loss: 2.8938\n",
            "Epoch [20/20], Loss: 1.7865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_sequence, word_to_index, index_to_word, vocab_size, max_len=20):\n",
        "    model.eval()\n",
        "    sequence = [word_to_index[word] for word in start_sequence if word in word_to_index]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        # Convert sequence to tensor\n",
        "        input_seq = torch.tensor(sequence[-sequence_length:], dtype=torch.long).unsqueeze(0)  # Shape: [1, seq_len]\n",
        "\n",
        "        # Predict next word\n",
        "        with torch.no_grad():\n",
        "            output = model(input_seq)\n",
        "            predicted_idx = torch.argmax(output, dim=1).item()\n",
        "            predicted_word = index_to_word[predicted_idx]\n",
        "\n",
        "        # Append predicted word\n",
        "        sequence.append(predicted_idx)\n",
        "\n",
        "        # Stop if end of sequence\n",
        "        if predicted_word == '<end>':\n",
        "            break\n",
        "\n",
        "    return ' '.join([index_to_word[idx] for idx in sequence])\n"
      ],
      "metadata": {
        "id": "W83sShgYJDyD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting sequence for prediction\n",
        "start_sequence = ['hello', 'my', 'name', 'is', 'pytorch']\n",
        "generated_text = generate_text(model, start_sequence, word_to_index, index_to_word, vocab_size, max_len=10)\n",
        "print(f'Generated text: {generated_text}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeRrXiMBJunZ",
        "outputId": "3808b7d9-659e-487b-cd19-e965f6f17019"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: my name is life away and sound so rivulet all we we have\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Model Implementation\n",
        "# Model parameters\n",
        "embedding_dim = 64    # Embedding dimension\n",
        "hidden_size = 128     # Hidden size of RNN/LSTM\n",
        "output_size = vocab_size\n",
        "num_layers = 2\n",
        "model_type = 'RNN'  # Choose between 'RNN' and 'LSTM'\n",
        "\n",
        "# Instantiate model\n",
        "model = EmbeddingRNNModel(vocab_size, embedding_dim, hidden_size, output_size, num_layers, model_type)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "TsVd8Mw9Jx52"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset\n",
        "class PoetryDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = PoetryDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "lQNRVVR1M4d7"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_epochs = 20\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        # Forward pass\n",
        "        outputs = model(X_batch)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, y_batch)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfymB0b0M_K2",
        "outputId": "97f8ad09-7a71-494e-e0bc-e19221d6cfa3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/20], Loss: 5.5937\n",
            "Epoch [10/20], Loss: 3.6830\n",
            "Epoch [15/20], Loss: 1.5059\n",
            "Epoch [20/20], Loss: 0.6751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_sequence, word_to_index, index_to_word, vocab_size, max_len=20):\n",
        "    model.eval()\n",
        "    sequence = [word_to_index[word] for word in start_sequence if word in word_to_index]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        # Convert sequence to tensor\n",
        "        input_seq = torch.tensor(sequence[-sequence_length:], dtype=torch.long).unsqueeze(0)  # Shape: [1, seq_len]\n",
        "\n",
        "        # Predict next word\n",
        "        with torch.no_grad():\n",
        "            output = model(input_seq)\n",
        "            predicted_idx = torch.argmax(output, dim=1).item()\n",
        "            predicted_word = index_to_word[predicted_idx]\n",
        "\n",
        "        # Append predicted word\n",
        "        sequence.append(predicted_idx)\n",
        "\n",
        "        # Stop if end of sequence\n",
        "        if predicted_word == '<end>':\n",
        "            break\n",
        "\n",
        "    return ' '.join([index_to_word[idx] for idx in sequence])"
      ],
      "metadata": {
        "id": "xzkVnL47NFNs"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting sequence for prediction\n",
        "start_sequence = ['hello', 'my', 'name', 'is', 'pytorch']\n",
        "generated_text = generate_text(model, start_sequence, word_to_index, index_to_word, vocab_size, max_len=10)\n",
        "print(f'Generated text: {generated_text}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhxQU77NNJPd",
        "outputId": "c0f098ba-5155-4209-9450-bfea09f291e0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: my name is she will there is limitless time around that love on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DnkofAS5NOD4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
